# user_data/TFT_PPO_Training/configs/optuna_config.yml
optuna:
  study_name: "PPO_TFT_Optimization"
  direction: "maximize"
  storage: "sqlite:///user_data/TFT_PPO_Training/logs/optuna_studies/ppo_tft.db"
  n_trials: 20
  timeout: 14400      # 초 단위 (4시간)

  sampler:
    type: "TPESampler"
    seed: 42

  pruner:
    type: "MedianPruner"
    n_startup_trials: 5
    n_warmup_steps: 3

  search_space:
    learning_rate:
      type: "loguniform"
      low: 1e-6
      high: 1e-3
    gamma:
      type: "uniform"
      low: 0.90
      high: 0.99
    clip_range:
      type: "uniform"
      low: 0.1
      high: 0.4
    ent_coef:
      type: "uniform"
      low: 0.0
      high: 0.02
    batch_size:
      type: "categorical"
      choices: [128, 256, 512]
