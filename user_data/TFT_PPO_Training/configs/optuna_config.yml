# user_data/TFT_PPO_Training/configs/optuna_config.yml
optuna:
  study_name: "PPO_TFT_KPI_Optimization"
  direction: "maximize"
  storage: "sqlite:///user_data/TFT_PPO_Training/logs/optuna_studies/ppo_tft.db"
  n_trials: 20
  timeout: 14400
  n_jobs: 1
  eval_freq: 10000
  eval_episodes: 3
  sampler:
    type: "TPESampler"
    seed: 42
  pruner:
    type: "SuccessiveHalvingPruner"
    min_resource: 1
    reduction_factor: 3
  search_space:
    learning_rate: { type: "loguniform", low: 5.0e-5, high: 1.0e-3 }
    gamma:         { type: "uniform",    low: 0.90,  high: 0.99 }
    clip_range:    { type: "uniform",    low: 0.1,   high: 0.4 }
    ent_coef:      { type: "uniform",    low: 0.02,  high: 0.15 }
    batch_size:    { type: "categorical", choices: [256, 512, 1024] }
    vf_coef:       { type: "uniform",    low: 0.3,   high: 1.2 }
    max_grad_norm: { type: "uniform",    low: 0.2,   high: 1.0 }
